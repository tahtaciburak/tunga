{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import numpy\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(filename):\n",
    "        # open the file\n",
    "        file = open(filename, mode='rt', encoding='utf-8')\n",
    "        \n",
    "        # read all text\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a text into sentences\n",
    "def to_lines(text):\n",
    "      sents = text.strip().split('\\n')\n",
    "      sents = [i.split('\\t') for i in sents]\n",
    "      return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_text(\"tur.txt\")\n",
    "tur_eng = to_lines(data)\n",
    "tur_eng = array(tur_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tur_eng = tur_eng[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tur_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_eng=[]\n",
    "for i in tur_eng:\n",
    "    i=i[:-1]\n",
    "    tr_eng.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tur_eng = numpy.array(tr_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513443, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tur_eng.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tur_eng[:,0] = [s.lower().translate(str.maketrans('', '', string.punctuation)) for s in tur_eng[:,0]]\n",
    "tur_eng[:,1] = [s.lower().translate(str.maketrans('', '', string.punctuation)) for s in tur_eng[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['hi', 'merhaba'],\n",
       "       ['hi', 'selam'],\n",
       "       ['run', 'kaç'],\n",
       "       ...,\n",
       "       ['if you want to sound like a native speaker you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo',\n",
       "        'eğer bir yerli gibi konuşmak istiyorsan banjo çalanların aynı parçayı onu doğru ve istenilen tempoda çalabilinceye kadar defalarca pratik yaptıkları aynı şekilde söylemeyi pratik yapmaya istekli olmalısın'],\n",
       "       ['if someone who doesnt know your background says that you sound like a native speaker it means they probably noticed something about your speaking that made them realize you werent a native speaker in other words you dont really sound like a native speaker',\n",
       "        'senin geçmiş deneyimini bilmeyen biri senin bir yerli konuşmacı gibi konuştuğunu söylerse bu senin bir yerli konuşmacı olmadığını onlara fark ettiren konuşman hakkında muhtemelen bir şey fark ettiği anlamına geliryani senin gerçekten yerli konuşmacı gibi konuşmadığını'],\n",
       "       ['doubtless there exists in this world precisely the right woman for any given man to marry and vice versa but when you consider that a human being has the opportunity of being acquainted with only a few hundred people and out of the few hundred that there are but a dozen or less whom he knows intimately and out of the dozen one or two friends at most it will easily be seen when we remember the number of millions who inhabit this world that probably since the earth was created the right man has never yet met the right woman',\n",
       "        'kuşkusuz bu dünyada her erkeğin ve kadının evlenmek için huyu huyuna suyu suyuna tamamen denk birisi mutlaka vardır fakat bir insanın sadece birkaç yüz kişiyle tanışma fırsatı bulduğu bu birkaç yüz kişi içinden belki bir düzinesini yakından tanıdığı bu bir düzinenin de ancak birkaçıyla dost olduğu göz önüne alınır ve de dünyada milyonlarca insanın yaşadığı hatırda tutulursa kolayca görülür ki dünya yaratıldığından beri doğru erkek doğru kadınla muhtemelen daha hiç karşılaşmamıştır']],\n",
       "      dtype='<U537')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tur_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_l = []\n",
    "tur_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in tur_eng[:,0]:\n",
    "    eng_l.append(len(i.split()))\n",
    "\n",
    "for i in tur_eng[:,1]:\n",
    "    tur_l.append(len(i.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df = pd.DataFrame({'eng':eng_l, 'tur':tur_l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_df.hist(bins = 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 21981\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = tokenization(tur_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 10\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turkish Vocabulary Size: 97062\n"
     ]
    }
   ],
   "source": [
    "# prepare Deutch tokenizer\n",
    "tur_tokenizer = tokenization(tur_eng[:, 1])\n",
    "tur_vocab_size = len(tur_tokenizer.word_index) + 1\n",
    "\n",
    "tur_length = 10\n",
    "print('Turkish Vocabulary Size: %d' % tur_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    seq = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(tur_eng, test_size=0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "trainX = encode_sequences(tur_tokenizer, tur_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare validation data\n",
    "testX = encode_sequences(tur_tokenizer, tur_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build NMT model\n",
    "def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(RepeatVector(out_timesteps))\n",
    "    model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(Dense(out_vocab, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(tur_vocab_size, eng_vocab_size, tur_length, eng_length, 1024)\n",
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model.h1.9_jl_20'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "history = model.fit(\n",
    "        trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n",
    "          epochs=20, batch_size=1024, \n",
    "          validation_split = 0.1,\n",
    "          callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model('model.h1.9_jl_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = encode_sequences(tur_tokenizer, tur_length, [\"bu durum beni mutlu etti\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_classes(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == n:\n",
    "            return word\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_text = []\n",
    "for i in preds:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], eng_tokenizer)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)\n",
    "             \n",
    "        else:\n",
    "            if(t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)            \n",
    "        \n",
    "    preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred=model.predict(str_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_text = []\n",
    "for i in preds:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], eng_tokenizer)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)\n",
    "             \n",
    "        else:\n",
    "            if(t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)            \n",
    "        \n",
    "    preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
